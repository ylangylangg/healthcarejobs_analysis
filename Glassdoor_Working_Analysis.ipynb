{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c13c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2ddaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Enhanced Glassdoor jobs scraper...\n",
      "Loaded initial page: https://www.glassdoor.sg/Job/singapore-analytics-internship-jobs-SRCH_IL.0,9_IC3235921_KO10,30.htm\n",
      "Jobs found so far: 0\n",
      "Found job listings using selector: li[data-test='jobListing']\n",
      "Found 30 total job listings\n",
      "Processing new job: 1\n",
      "  Added job: Social Media Manager Intern at The Plexxie Global Company Pte. Ltd.\n",
      "Processing new job: 2\n",
      "  Added job: Senior Executive Assistant at PERSOL\n",
      "3.5\n",
      "Processing new job: 3\n",
      "  Added job: SATS Internship at SATS\n",
      "3.3\n",
      "Processing new job: 4\n",
      "  Added job: Aon Internship Programme 2026, Singapore - Innovation & Analytics at Aon Corporation\n",
      "3.8\n",
      "Processing new job: 5\n",
      "  Added job: Summer Internship 2026 - External Fund Management at Income Insurance Limited\n",
      "3.5\n",
      "Processing new job: 6\n",
      "  Added job: Data Analyst (Internship) at Infosys Singapore & Australia\n",
      "3.6\n",
      "Processing new job: 7\n",
      "  Added job: Data Analyst (Internship) at ShopBack\n",
      "3.5\n",
      "Processing new job: 8\n",
      "  Added job: Internship: Global Wholesale Banking, Data Analytics [January â€“ May 2026] at OCBC Bank\n",
      "3.4\n",
      "Processing new job: 9\n",
      "  Added job: Data Analytics Intern at AIKIT PTE. LTD.\n",
      "Processing new job: 10\n",
      "  Added job: Business Data Analyst Project Intern (GBS) - 2026 Start (BS/MS) at TikTok\n",
      "3.2\n",
      "Processing new job: 11\n",
      "  Added job: Summer Internship 2026 - Innovation & Analytics at Income Insurance Limited\n",
      "3.5\n",
      "Processing new job: 12\n",
      "  Added job: Summer Internship 2026 - Data Scientist at Income Insurance Limited\n",
      "3.5\n",
      "Processing new job: 13\n",
      "  Added job: Internship - Data Analytics and Gen AI for Audit & Assurance, Singapore (July to December 2026) at GSK\n",
      "4.0\n",
      "Processing new job: 14\n",
      "  Added job: Data Intelligence Intern at Publicis Groupe Holdings B.V\n",
      "3.8\n",
      "Processing new job: 15\n",
      "  Added job: Data Science Intern (Semester 2026) - P&G Management Internship Program - Bachelor's Degree or above at Procter & Gamble\n",
      "4.1\n",
      "Processing new job: 16\n",
      "  Added job: Data Analytics & Project Management (AI) Intern - Travel Retail at Parfums Christian Dior (PCD)\n",
      "3.6\n",
      "Processing new job: 17\n",
      "  Added job: Financial Product Intern (Summer Internship) at Funding Societies | Modalku Group\n",
      "3.1\n",
      "Processing new job: 18\n",
      "  Added job: One Deals Summer Internship (May - Aug 26) at PwC\n",
      "3.7\n",
      "Processing new job: 19\n",
      "  Added job: Employment Type Internship at Maritime Singapore Connect\n",
      "Processing new job: 20\n",
      "  Added job: Summer Internship 2026 - Data Governance at Income Insurance Limited\n",
      "3.5\n",
      "Processing new job: 21\n",
      "  Added job: Wealth - Citigold, Summer Analyst, Singapore, 2026 at Citi\n",
      "3.7\n",
      "Processing new job: 22\n",
      "  Added job: Internship Program, Data Science at Louis Dreyfus Company\n",
      "4.1\n",
      "Processing new job: 23\n",
      "  Added job: Business Analyst, Shopee COO Office (2026 Graduates) at Shopee\n",
      "3.7\n",
      "Processing new job: 24\n",
      "  Added job: Wealth and Retail Banking Internship Programme Singapore 2026 at Standard Chartered\n",
      "3.8\n",
      "Processing new job: 25\n",
      "  Added job: Financial Markets Internship Programme Singapore 2026 at Standard Chartered\n",
      "3.8\n",
      "Processing new job: 26\n",
      "  Added job: Business Intelligence Demand Intern at Guerlain\n",
      "4.0\n",
      "Processing new job: 27\n",
      "  Added job: IT Commercial Analytics Intern (Semester 2026) - P&G Management Internship Program at Procter & Gamble\n",
      "4.1\n",
      "Processing new job: 28\n",
      "  Added job: (Internship) Business Solution Delivery Associate / Project Management at SWAT Mobility Pte. Ltd.\n",
      "4.9\n",
      "Processing new job: 29\n",
      "  Added job: Data Analyst / Data Science Intern at Suntory Oceania\n",
      "3.6\n",
      "Processing new job: 30\n",
      "  Added job: Intern, Data Analyst at Bosch Group\n",
      "4.0\n",
      "Processed 30 new jobs\n",
      "Found 'Show More Jobs' button using selector: button[data-test='load-more']\n",
      "Clicked 'Show More Jobs' (attempt 1/60)\n",
      "Jobs found so far: 30\n",
      "Found job listings using XPath: //li[.//a[contains(@href, '/job/') or contains(@href, '/Job/')]]\n",
      "Found 1 total job listings\n",
      "Processing new job: 1\n",
      "No new jobs found on this page\n",
      "Could not find or click 'Show More Jobs' button\n",
      "Completed scraping. Collected 30 jobs.\n",
      "Successfully saved 30 jobs to glassdoor__jobs_detailed_20260106_164132.csv\n",
      "\n",
      "Summary of scraped data:\n",
      "Total jobs found: 30\n",
      "\n",
      "Top companies:\n",
      "  Income Insurance Limited\n",
      "3.5: 4 jobs\n",
      "  Procter & Gamble\n",
      "4.1: 2 jobs\n",
      "  Standard Chartered\n",
      "3.8: 2 jobs\n",
      "  The Plexxie Global Company Pte. Ltd.: 1 jobs\n",
      "  PERSOL\n",
      "3.5: 1 jobs\n"
     ]
    }
   ],
   "source": [
    "### 1. Function: CSV SAVERR\n",
    "def save_to_csv(jobs, filename=None):\n",
    "    \"\"\"Save the scraped jobs to a CSV file\"\"\"\n",
    "    if not jobs:\n",
    "        print(\"No jobs to save\")\n",
    "        return False\n",
    "    \n",
    "    if filename is None:\n",
    "        # Create a filename with timestamp\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f'glassdoor_healthcare_jobs_{timestamp}.csv'\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "            # Get all possible keys from all jobs\n",
    "            fieldnames = set()\n",
    "            for job in jobs:\n",
    "                fieldnames.update(job.keys())\n",
    "            \n",
    "            writer = csv.DictWriter(file, fieldnames=list(fieldnames))\n",
    "            writer.writeheader()\n",
    "            writer.writerows(jobs)\n",
    "        \n",
    "        print(f\"Successfully saved {len(jobs)} jobs to {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "### 2. Function: Enhanced Scraper\n",
    "\n",
    "def enhanced_scraper(max_jobs=None, max_show_more_attempts=60, get_job_details=True):\n",
    "    \"\"\"Enhanced scraper that efficiently processes jobs and extracts detailed information\n",
    "    \n",
    "    Args:\n",
    "        max_jobs (int, optional): Maximum number of jobs to scrape. Default is None (no limit).\n",
    "        max_show_more_attempts (int, optional): Maximum number of times to click 'Show More Jobs'. Default is 60.\n",
    "        get_job_details (bool, optional): Whether to extract detailed job information. Default is True.\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--disable-popup-blocking\")\n",
    "    \n",
    "    # Add user agent - use a more recent one\n",
    "    user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "    options.add_argument(f\"user-agent={user_agent}\")\n",
    "    \n",
    "    # Add additional options to make the browser less detectable\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    \n",
    "    try:\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "        # Execute script to make the webdriver undetectable\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        \n",
    "        # Load page\n",
    "        url = \"https://www.glassdoor.sg/Job/singapore-analytics-internship-jobs-SRCH_IL.0,9_IC3235921_KO10,30.htm\"\n",
    "        driver.get(url)\n",
    "        print(f\"Loaded initial page: {url}\")\n",
    "        \n",
    "        # Wait longer for initial load\n",
    "        time.sleep(15)\n",
    "        \n",
    "        # Initialize list to store job data\n",
    "        jobs_data = []\n",
    "        processed_jobs = set()  # Keep track of which jobs we've already processed\n",
    "        show_more_attempts = 0\n",
    "        \n",
    "        # Main loop for pagination through job listings\n",
    "        while True:\n",
    "            print(f\"Jobs found so far: {len(jobs_data)}\")\n",
    "            \n",
    "            # Check if we've reached the maximum job limit\n",
    "            if max_jobs and len(jobs_data) >= max_jobs:\n",
    "                print(f\"Reached configured maximum of {max_jobs} jobs\")\n",
    "                break\n",
    "                \n",
    "            # Check if we've exceeded maximum scroll attempts\n",
    "            if show_more_attempts >= max_show_more_attempts:\n",
    "                print(f\"Reached maximum 'Show More Jobs' attempts ({max_show_more_attempts})\")\n",
    "                break\n",
    "            \n",
    "            # Close any modals that might appear\n",
    "            close_modals(driver)\n",
    "            \n",
    "            # Find all job listings\n",
    "            job_listings = find_job_listings(driver)\n",
    "            if not job_listings:\n",
    "                print(\"Could not find any job listings\")\n",
    "                break\n",
    "                \n",
    "            print(f\"Found {len(job_listings)} total job listings\")\n",
    "            \n",
    "            # Process new jobs (ones we haven't seen before)\n",
    "            if get_job_details:\n",
    "                # Detailed mode: Click on each new job to get full details\n",
    "                new_jobs_processed = process_detailed_jobs(driver, job_listings, jobs_data, processed_jobs)\n",
    "            else:\n",
    "                # Simple mode: Just extract card information without clicking\n",
    "                new_jobs_processed = process_basic_jobs(driver, job_listings, jobs_data, processed_jobs)\n",
    "            \n",
    "            if new_jobs_processed == 0:\n",
    "                print(\"No new jobs found on this page\")\n",
    "            else:\n",
    "                print(f\"Processed {new_jobs_processed} new jobs\")\n",
    "                \n",
    "            # Try to load more jobs\n",
    "            more_jobs_clicked = click_show_more_jobs(driver)\n",
    "            \n",
    "            if more_jobs_clicked:\n",
    "                show_more_attempts += 1\n",
    "                print(f\"Clicked 'Show More Jobs' (attempt {show_more_attempts}/{max_show_more_attempts})\")\n",
    "                time.sleep(5)  # Wait for new jobs to load\n",
    "            else:\n",
    "                print(\"Could not find or click 'Show More Jobs' button\")\n",
    "                # No need for pagination attempts since we're focused on \"Show More Jobs\"\n",
    "                break\n",
    "        \n",
    "        print(f\"Completed scraping. Collected {len(jobs_data)} jobs.\")\n",
    "        return jobs_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Critical error: {e}\")\n",
    "        return []\n",
    "    \n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "### 3. Function: Job Listing\n",
    "\n",
    "def find_job_listings(driver):\n",
    "    \"\"\"Find all job listings on the current page\"\"\"\n",
    "    job_listings = []\n",
    "    \n",
    "    # Try multiple selectors to find job listings\n",
    "    selectors_to_try = [\n",
    "        \"li[data-test='jobListing']\",\n",
    "        \".react-job-listing\",\n",
    "        \".jobCard\",\n",
    "        \"div[data-job-id]\",\n",
    "        \"li[class*='jobListItem']\",\n",
    "        \"li[data-brandviews*='jsearch-job-listing']\"\n",
    "    ]\n",
    "    \n",
    "    for selector in selectors_to_try:\n",
    "        try:\n",
    "            # Use a shorter timeout for each attempt\n",
    "            job_listings = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            if job_listings and len(job_listings) > 0:\n",
    "                print(f\"Found job listings using selector: {selector}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # If we still didn't find anything, try XPath as a last resort\n",
    "    if not job_listings:\n",
    "        xpaths_to_try = [\n",
    "            \"//li[contains(@class, 'job') and contains(@class, 'list')]\",\n",
    "            \"//li[contains(@data-brandviews, 'job-listing')]\",\n",
    "            \"//div[contains(@class, 'job') and contains(@class, 'card')]\",\n",
    "            \"//li[.//a[contains(@href, '/job/') or contains(@href, '/Job/')]]\"\n",
    "        ]\n",
    "        \n",
    "        for xpath in xpaths_to_try:\n",
    "            try:\n",
    "                job_listings = WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, xpath))\n",
    "                )\n",
    "                if job_listings and len(job_listings) > 0:\n",
    "                    print(f\"Found job listings using XPath: {xpath}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    return job_listings\n",
    "### 4. Function: New Job Processor\n",
    "def process_basic_jobs(driver, job_listings, jobs_data, processed_jobs):\n",
    "    \"\"\"Process only the new jobs that haven't been seen before (basic info only)\"\"\"\n",
    "    new_jobs_processed = 0\n",
    "    \n",
    "    for job in job_listings:\n",
    "        # Try to get a unique identifier for this job\n",
    "        job_id = get_job_identifier(job)\n",
    "        \n",
    "        # Skip if we've already processed this job\n",
    "        if job_id in processed_jobs:\n",
    "            continue\n",
    "            \n",
    "        # Process this job\n",
    "        print(f\"Processing new job: {new_jobs_processed + 1}\")\n",
    "        \n",
    "        # Scroll to ensure the job is visible\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", job)\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Extract job details\n",
    "        job_data = extract_job_data(job)\n",
    "        \n",
    "        if job_data and (job_data.get(\"title\") != \"Unknown Title\" or job_data.get(\"company\") != \"Unknown Company\"):\n",
    "            # Add to our results and mark as processed\n",
    "            jobs_data.append(job_data)\n",
    "            processed_jobs.add(job_id)\n",
    "            print(f\"  Added job: {job_data.get('title', 'Unknown')} at {job_data.get('company', 'Unknown')}\")\n",
    "            new_jobs_processed += 1\n",
    "        \n",
    "        # Small delay between jobs\n",
    "        time.sleep(random.uniform(0.3, 0.7))\n",
    "    \n",
    "    return new_jobs_processed\n",
    "### 5, Function: Process jobs and click each one to get detailed information\n",
    "def process_detailed_jobs(driver, job_listings, jobs_data, processed_jobs):\n",
    "    \"\"\"Process jobs and click each one to get detailed information\"\"\"\n",
    "    new_jobs_processed = 0\n",
    "    \n",
    "    for job in job_listings:\n",
    "        try:\n",
    "            # Try to get a unique identifier for this job\n",
    "            job_id = get_job_identifier(job)\n",
    "            \n",
    "            # Skip if we've already processed this job\n",
    "            if job_id in processed_jobs:\n",
    "                continue\n",
    "                \n",
    "            # Process this job\n",
    "            print(f\"Processing new job: {new_jobs_processed + 1}\")\n",
    "            \n",
    "            # First extract basic data from the card\n",
    "            job_data = extract_job_data(job)\n",
    "            \n",
    "            if not job_data or (job_data.get(\"title\") == \"Unknown Title\" and job_data.get(\"company\") == \"Unknown Company\"):\n",
    "                continue\n",
    "                \n",
    "            # Find the clickable element to open the job details\n",
    "            click_success = click_job_listing(driver, job)\n",
    "            \n",
    "            if click_success:\n",
    "                # Wait for job details to load\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-test='jobDescriptionContent'], .jobDescriptionContent\"))\n",
    "                    )\n",
    "                    \n",
    "                    # Handle the \"Show more\" button in job description if present\n",
    "                    click_show_more_in_description(driver)\n",
    "                    \n",
    "                    # Extract detailed job information\n",
    "                    detailed_info = extract_detailed_job_info(driver)\n",
    "                    \n",
    "                    # Add detailed info to job data\n",
    "                    job_data.update(detailed_info)\n",
    "                    \n",
    "                    print(f\"  Added detailed info for: {job_data.get('title')}\")\n",
    "                    \n",
    "                    # Go back to job list\n",
    "                    # Sometimes a back button is available, other times need to use browser back\n",
    "                    try:\n",
    "                        back_button = driver.find_element(By.CSS_SELECTOR, \"button[data-test='back-to-SRP'], .backButton\")\n",
    "                        back_button.click()\n",
    "                        time.sleep(2)\n",
    "                    except:\n",
    "                        driver.back()\n",
    "                        time.sleep(3)\n",
    "                    \n",
    "                    # Wait for job listings to be visible again\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"li[data-test='jobListing']\"))\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error extracting detailed info: {e}\")\n",
    "                    driver.back()\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "                    # Wait for listings to be visible again\n",
    "                    try:\n",
    "                        WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.CSS_SELECTOR, \"li[data-test='jobListing']\"))\n",
    "                        )\n",
    "                    except:\n",
    "                        # If we can't get back to listings, refresh the page\n",
    "                        current_url = driver.current_url\n",
    "                        driver.get(current_url)\n",
    "                        time.sleep(5)\n",
    "            \n",
    "            # Add job data to results and mark as processed\n",
    "            jobs_data.append(job_data)\n",
    "            processed_jobs.add(job_id)\n",
    "            new_jobs_processed += 1\n",
    "            \n",
    "            # Small delay between jobs\n",
    "            time.sleep(random.uniform(1.0, 2.0))\n",
    "            \n",
    "            # Get fresh job listings after browser navigation\n",
    "            if new_jobs_processed % 5 == 0:\n",
    "                # Refresh job listings every 5 jobs to avoid stale elements\n",
    "                return new_jobs_processed\n",
    "                \n",
    "        except StaleElementReferenceException:\n",
    "            print(\"  Job element became stale, continuing to next job\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing job: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return new_jobs_processed\n",
    "### 6. Function: Job listing detail opener\n",
    "def click_job_listing(driver, job_element):\n",
    "    \"\"\"Click on a job listing to open its details\"\"\"\n",
    "    try:\n",
    "        # Try to find the clickable element within the job listing\n",
    "        clickable_selectors = [\n",
    "            \"a[data-test='job-link']\",\n",
    "            \"a.jobLink\",\n",
    "            \"a[href*='/job/']\",\n",
    "            \"h2 a\",\n",
    "            \"h3 a\",\n",
    "            \".jobTitle a\"\n",
    "        ]\n",
    "        \n",
    "        for selector in clickable_selectors:\n",
    "            try:\n",
    "                clickable = job_element.find_element(By.CSS_SELECTOR, selector)\n",
    "                if clickable and clickable.is_displayed():\n",
    "                    # Scroll to element\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", clickable)\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # Try clicking with JavaScript (most reliable)\n",
    "                    driver.execute_script(\"arguments[0].click();\", clickable)\n",
    "                    time.sleep(3)\n",
    "                    return True\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        # If all selectors failed, try clicking the job element itself\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", job_element)\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", job_element)\n",
    "        time.sleep(3)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error clicking job listing: {e}\")\n",
    "        return False\n",
    "### 7, Function: Click on 'Show more' button in job description if present\n",
    "def click_show_more_in_description(driver):\n",
    "    \"\"\"Click on 'Show more' button in job description if present\"\"\"\n",
    "    try:\n",
    "        # Wait briefly to see if a \"Show more\" button appears\n",
    "        show_more_buttons = driver.find_elements(By.XPATH, \n",
    "            \"//button[contains(., 'Show more') and not(contains(., 'jobs'))]\")\n",
    "        \n",
    "        if not show_more_buttons:\n",
    "            # Try alternative selectors\n",
    "            show_more_buttons = driver.find_elements(By.CSS_SELECTOR, \n",
    "                \"button.showMore, button[data-test='show-more-content'], button.css-n2dhtq\")\n",
    "        \n",
    "        if show_more_buttons:\n",
    "            for button in show_more_buttons:\n",
    "                if button.is_displayed() and button.is_enabled():\n",
    "                    print(\"  Found 'Show more' button in job description\")\n",
    "                    \n",
    "                    # Scroll to button\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button)\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # Click with JavaScript\n",
    "                    driver.execute_script(\"arguments[0].click();\", button)\n",
    "                    print(\"  Expanded job description\")\n",
    "                    time.sleep(2)\n",
    "                    return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error clicking 'Show more' in description: {e}\")\n",
    "        return False\n",
    "\n",
    "### 8. Function: Extract detailed job information from the job details page\n",
    "def extract_detailed_job_info(driver):\n",
    "    \"\"\"Extract detailed job information from the job details page\"\"\"\n",
    "    detailed_info = {}\n",
    "    \n",
    "    try:\n",
    "        # Job Description\n",
    "        description_selectors = [\n",
    "            \"div[data-test='jobDescriptionContent']\",\n",
    "            \".jobDescriptionContent\",\n",
    "            \"#JobDescriptionContainer\",\n",
    "            \"[data-test='job-description']\"\n",
    "        ]\n",
    "        \n",
    "        for selector in description_selectors:\n",
    "            try:\n",
    "                description_elem = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                detailed_info[\"description\"] = description_elem.text\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        if \"description\" not in detailed_info:\n",
    "            detailed_info[\"description\"] = \"No description available\"\n",
    "        \n",
    "        # Extract more structured information\n",
    "        \n",
    "        # Job Type\n",
    "        try:\n",
    "            job_type_elements = driver.find_elements(By.XPATH, \n",
    "                \"//*[contains(text(), 'Job Type') or contains(text(), 'Employment Type')]/following-sibling::*\")\n",
    "            \n",
    "            if job_type_elements:\n",
    "                detailed_info[\"job_type\"] = job_type_elements[0].text.strip()\n",
    "            else:\n",
    "                # Alternative approach\n",
    "                employment_info = driver.find_elements(By.CSS_SELECTOR, \".css-1cz2bp4, .css-1pldt9b, .css-1vg6q84\")\n",
    "                for elem in employment_info:\n",
    "                    text = elem.text.strip()\n",
    "                    if \"Full-time\" in text or \"Part-time\" in text or \"Contract\" in text or \"Permanent\" in text:\n",
    "                        detailed_info[\"job_type\"] = text\n",
    "                        break\n",
    "        except:\n",
    "            detailed_info[\"job_type\"] = \"Not specified\"\n",
    "        \n",
    "        # Experience Level\n",
    "        try:\n",
    "            exp_elements = driver.find_elements(By.XPATH, \"//*[contains(text(), 'Experience')]/following-sibling::*\")\n",
    "            if exp_elements:\n",
    "                detailed_info[\"experience\"] = exp_elements[0].text.strip()\n",
    "        except:\n",
    "            detailed_info[\"experience\"] = \"Not specified\"\n",
    "        \n",
    "        # Education\n",
    "        try:\n",
    "            edu_elements = driver.find_elements(By.XPATH, \"//*[contains(text(), 'Education')]/following-sibling::*\")\n",
    "            if edu_elements:\n",
    "                detailed_info[\"education\"] = edu_elements[0].text.strip()\n",
    "        except:\n",
    "            detailed_info[\"education\"] = \"Not specified\"\n",
    "        \n",
    "        # Industry\n",
    "        try:\n",
    "            industry_elements = driver.find_elements(By.XPATH, \"//*[contains(text(), 'Industry')]/following-sibling::*\")\n",
    "            if industry_elements:\n",
    "                detailed_info[\"industry\"] = industry_elements[0].text.strip()\n",
    "        except:\n",
    "            detailed_info[\"industry\"] = \"Not specified\"\n",
    "        \n",
    "        # Benefits\n",
    "        try:\n",
    "            benefits_container = driver.find_elements(By.CSS_SELECTOR, \n",
    "                \".jobDetails-benefits, .css-1jnzwkp, [data-test='benefits']\")\n",
    "            \n",
    "            benefits = []\n",
    "            if benefits_container:\n",
    "                benefit_elements = benefits_container[0].find_elements(By.CSS_SELECTOR, \"li, span\")\n",
    "                for elem in benefit_elements:\n",
    "                    benefits.append(elem.text.strip())\n",
    "                \n",
    "                detailed_info[\"benefits\"] = \", \".join([b for b in benefits if b])\n",
    "            else:\n",
    "                detailed_info[\"benefits\"] = \"Not listed\"\n",
    "        except:\n",
    "            detailed_info[\"benefits\"] = \"Not listed\"\n",
    "        \n",
    "        # Extract additional fields\n",
    "        \n",
    "        # Check for common sections in job descriptions\n",
    "        description_text = detailed_info[\"description\"].lower()\n",
    "        \n",
    "        # Look for Requirements section\n",
    "        requirements = []\n",
    "        if \"requirements:\" in description_text or \"qualifications:\" in description_text:\n",
    "            lines = detailed_info[\"description\"].split('\\n')\n",
    "            in_requirements_section = False\n",
    "            \n",
    "            for line in lines:\n",
    "                line_lower = line.lower().strip()\n",
    "                \n",
    "                if line_lower.startswith(\"requirements:\") or line_lower.startswith(\"qualifications:\"):\n",
    "                    in_requirements_section = True\n",
    "                    requirements.append(line.replace(\"Requirements:\", \"\").replace(\"Qualifications:\", \"\").strip())\n",
    "                    continue\n",
    "                elif in_requirements_section and (line_lower.startswith(\"responsibilities:\") or \n",
    "                          line_lower.startswith(\"about the role:\") or \n",
    "                          line_lower.startswith(\"about the job:\") or\n",
    "                          line_lower.startswith(\"what you'll do:\")):\n",
    "                    in_requirements_section = False\n",
    "                elif in_requirements_section and line.strip():\n",
    "                    requirements.append(line.strip())\n",
    "            \n",
    "            if requirements:\n",
    "                detailed_info[\"requirements\"] = \" \".join(requirements)\n",
    "        \n",
    "        return detailed_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error extracting detailed job info: {e}\")\n",
    "        return {\"description\": \"Error extracting details\"}\n",
    "### 9. Function: Create a unique identifier for a job element\n",
    "def get_job_identifier(job_element):\n",
    "    \"\"\"Create a unique identifier for a job element\"\"\"\n",
    "    # Try multiple approaches to get a unique ID\n",
    "    try:\n",
    "        # First try to get any ID attributes\n",
    "        job_id = job_element.get_attribute(\"id\")\n",
    "        if job_id:\n",
    "            return job_id\n",
    "            \n",
    "        # Try data-job-id\n",
    "        job_id = job_element.get_attribute(\"data-job-id\")\n",
    "        if job_id:\n",
    "            return job_id\n",
    "            \n",
    "        # Try data-id\n",
    "        job_id = job_element.get_attribute(\"data-id\")\n",
    "        if job_id:\n",
    "            return job_id\n",
    "        \n",
    "        # As a fallback, use a combination of title and company\n",
    "        title = extract_with_multiple_selectors(job_element, [\"a[data-test='job-link']\", \".job-title\", \"h2\"])\n",
    "        company = extract_with_multiple_selectors(job_element, [\"div[data-test='employer-name']\", \".employer-name\"])\n",
    "        \n",
    "        if title and company:\n",
    "            return f\"{title}|{company}\"\n",
    "            \n",
    "        # Last resort: use a portion of the element's HTML\n",
    "        return hash(job_element.get_attribute(\"outerHTML\")[:200])  # First 200 chars should be distinctive enough\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If all else fails, use a random ID (better than nothing)\n",
    "        return f\"random-{random.randint(10000, 99999)}\"\n",
    "### 10. Function: Extract all relevant data from a job listing\n",
    "def extract_job_data(job):\n",
    "    \"\"\"Extract all relevant data from a job listing\"\"\"\n",
    "    job_data = {\n",
    "        \"scrape_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Get all text from the job element for fallback\n",
    "        all_text = job.text\n",
    "        \n",
    "        # Title\n",
    "        title_selectors = [\n",
    "            \"a[data-test='job-link']\", \n",
    "            \".job-title\", \n",
    "            \".jobTitle\", \n",
    "            \"a[href*='/job/']\",\n",
    "            \"[data-test='job-title']\",\n",
    "            \"h2\", \n",
    "            \"h3\"\n",
    "        ]\n",
    "        job_data[\"title\"] = extract_with_multiple_selectors(job, title_selectors) or \"Unknown Title\"\n",
    "        \n",
    "        # Company\n",
    "        company_selectors = [\n",
    "            \"div[data-test='employer-name']\",\n",
    "            \".employer-name\",\n",
    "            \".companyName\",\n",
    "            \"[data-test='company-name']\",\n",
    "            \".css-1vg6q84\",\n",
    "            \".e1n63ojh0\"\n",
    "        ]\n",
    "        job_data[\"company\"] = extract_with_multiple_selectors(job, company_selectors) or \"Unknown Company\"\n",
    "        \n",
    "        # Location\n",
    "        location_selectors = [\n",
    "            \"div[data-test='location']\",\n",
    "            \".location\",\n",
    "            \".css-56kyx5\",\n",
    "            \"[data-test='loc']\"\n",
    "        ]\n",
    "        job_data[\"location\"] = extract_with_multiple_selectors(job, location_selectors) or \"Unknown Location\"\n",
    "        \n",
    "        # Salary\n",
    "        salary_selectors = [\n",
    "            \"div[data-test='detailSalary']\",\n",
    "            \".salary\",\n",
    "            \".salaryEstimate\",\n",
    "            \"span[data-test='salary']\",\n",
    "            \".css-16u98uf\",\n",
    "            \".e1wijj240\"\n",
    "        ]\n",
    "        job_data[\"salary\"] = extract_with_multiple_selectors(job, salary_selectors) or \"Not Provided\"\n",
    "        \n",
    "        # Posted date\n",
    "        date_selectors = [\n",
    "            \"div[data-test='job-age']\",\n",
    "            \".job-age\",\n",
    "            \".listingAge\",\n",
    "            \"div[data-test='listing-age']\",\n",
    "            \".css-1u0budq\",\n",
    "            \".e1uvbk020\"\n",
    "        ]\n",
    "        job_data[\"posted_date\"] = extract_with_multiple_selectors(job, date_selectors) or \"Unknown\"\n",
    "        \n",
    "        # Rating\n",
    "        rating_selectors = [\n",
    "            \"span[data-test='detailRating']\",\n",
    "            \".rating\",\n",
    "            \".ratingNumber\",\n",
    "            \".css-152xdkl\",\n",
    "            \".e1pr2f4f2\"\n",
    "        ]\n",
    "        job_data[\"rating\"] = extract_with_multiple_selectors(job, rating_selectors) or \"Not Rated\"\n",
    "        \n",
    "        # If we failed to get title and company, try text fallback\n",
    "        if job_data[\"title\"] == \"Unknown Title\" and job_data[\"company\"] == \"Unknown Company\":\n",
    "            if all_text and len(all_text.strip()) > 0:\n",
    "                lines = all_text.strip().split('\\n')\n",
    "                if len(lines) >= 2:\n",
    "                    job_data[\"title\"] = lines[0]\n",
    "                    job_data[\"company\"] = lines[1]\n",
    "                    if len(lines) > 2:\n",
    "                        job_data[\"location\"] = lines[2]\n",
    "                \n",
    "        return job_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error extracting job data: {e}\")\n",
    "        return None\n",
    "### 11. Function: Try multiple selectors to extract text from an element\n",
    "def extract_with_multiple_selectors(element, selectors):\n",
    "    \"\"\"Try multiple selectors to extract text from an element\"\"\"\n",
    "    # Try CSS selectors\n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            found_element = element.find_element(By.CSS_SELECTOR, selector)\n",
    "            text = found_element.text.strip()\n",
    "            if text:\n",
    "                return text\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # If CSS selectors failed, try XPath as fallback\n",
    "    xpath_title = [\".//h2\", \".//h3\", \".//a[contains(@href, '/job/')]\"]\n",
    "    xpath_company = [\".//div[contains(@class, 'company')]\", \".//div[contains(@class, 'employer')]\"]\n",
    "    xpath_location = [\".//div[contains(@class, 'location')]\", \".//*[contains(@class, 'loc')]\"] \n",
    "    xpath_salary = [\".//span[contains(text(), '$')]\", \".//div[contains(text(), 'SGD')]\"]\n",
    "    xpath_date = [\".//div[contains(text(), 'd')]\", \".//div[contains(text(), 'h')]\"]\n",
    "    \n",
    "    # Determine which XPath patterns to try based on selector names\n",
    "    xpath_to_try = []\n",
    "    selector_text = \" \".join(selectors).lower()\n",
    "    \n",
    "    if \"title\" in selector_text or \"job\" in selector_text:\n",
    "        xpath_to_try.extend(xpath_title)\n",
    "    if \"company\" in selector_text or \"employer\" in selector_text:\n",
    "        xpath_to_try.extend(xpath_company)\n",
    "    if \"location\" in selector_text or \"loc\" in selector_text:\n",
    "        xpath_to_try.extend(xpath_location)\n",
    "    if \"salary\" in selector_text:\n",
    "        xpath_to_try.extend(xpath_salary)\n",
    "    if \"date\" in selector_text or \"age\" in selector_text:\n",
    "        xpath_to_try.extend(xpath_date)\n",
    "    \n",
    "    # Try the relevant XPaths\n",
    "    for xpath in xpath_to_try:\n",
    "        try:\n",
    "            found_element = element.find_element(By.XPATH, xpath)\n",
    "            text = found_element.text.strip()\n",
    "            if text:\n",
    "                return text\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "### 12. Function: Try to click the 'Show More Jobs' button\n",
    "def click_show_more_jobs(driver):\n",
    "    \"\"\"Try to click the 'Show More Jobs' button\"\"\"\n",
    "    try:\n",
    "        # Try multiple selectors for the button\n",
    "        show_more_selectors = [\n",
    "            \"button[data-test='load-more']\",\n",
    "            \"button.button_ButtonMlD2g\",\n",
    "            \"button[aria-live='polite']\",\n",
    "            \"button[data-test='show-more-jobs']\"\n",
    "        ]\n",
    "        \n",
    "        for selector in show_more_selectors:\n",
    "            try:\n",
    "                buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for btn in buttons:\n",
    "                    # Check if this button contains text about showing more jobs\n",
    "                    button_text = btn.text.lower()\n",
    "                    if \"show more jobs\" in button_text or \"load more\" in button_text:\n",
    "                        if btn.is_displayed() and btn.is_enabled():\n",
    "                            print(f\"Found 'Show More Jobs' button using selector: {selector}\")\n",
    "                            \n",
    "                            # Scroll to button\n",
    "                            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", btn)\n",
    "                            time.sleep(1)\n",
    "                            \n",
    "                            # Try clicking with JavaScript (most reliable method)\n",
    "                            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                            return True\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # If CSS selectors didn't work, try XPath\n",
    "        try:\n",
    "            xpath_buttons = driver.find_elements(By.XPATH, \n",
    "                \"//button[.//span[contains(text(), 'Show more jobs')]]\")\n",
    "            \n",
    "            if xpath_buttons:\n",
    "                for btn in xpath_buttons:\n",
    "                    if btn.is_displayed() and btn.is_enabled():\n",
    "                        print(\"Found 'Show More Jobs' button using XPath\")\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", btn)\n",
    "                        time.sleep(1)\n",
    "                        driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                        return True\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error looking for 'Show More Jobs' button: {e}\")\n",
    "        return False\n",
    "\n",
    "### 13. Function: Attempts to close any modal dialogs that might be present\n",
    "def close_modals(driver):\n",
    "    \"\"\"Attempts to close any modal dialogs that might be present\"\"\"\n",
    "    try:\n",
    "        # Look for common overlay elements\n",
    "        overlay_selectors = [\".ModalOverlay\", \".modal_main\", \"[role='dialog']\"]\n",
    "        overlay_found = False\n",
    "        \n",
    "        for selector in overlay_selectors:\n",
    "            try:\n",
    "                overlay = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                overlay_found = True\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        if not overlay_found:\n",
    "            return False\n",
    "        \n",
    "        # Try various close button selectors\n",
    "        close_selectors = [\n",
    "            \"button[aria-label='Close']\",\n",
    "            \".modal-close-btn\",\n",
    "            \".close\",\n",
    "            \"button.dismiss\",\n",
    "            \".modal_closeIcon\",\n",
    "            \".CloseButton\",\n",
    "            \"button.e1jbctw80\",\n",
    "            \"[alt='Close']\"\n",
    "        ]\n",
    "        \n",
    "        for selector in close_selectors:\n",
    "            try:\n",
    "                close_buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                if close_buttons:\n",
    "                    for button in close_buttons:\n",
    "                        try:\n",
    "                            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button)\n",
    "                            driver.execute_script(\"arguments[0].click();\", button)\n",
    "                            time.sleep(1)\n",
    "                            return True\n",
    "                        except:\n",
    "                            continue\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Add missing part - if no buttons worked\n",
    "        # Try ESC key\n",
    "        actions = webdriver.ActionChains(driver)\n",
    "        actions.send_keys(webdriver.Keys.ESCAPE).perform()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # JavaScript approach as last resort\n",
    "        script = \"\"\"\n",
    "        // Hide all possible modal/overlay elements\n",
    "        var overlays = document.querySelectorAll('.ModalOverlay, .modal, .popover, .dialog, [role=\"dialog\"]');\n",
    "        for (var i = 0; i < overlays.length; i++) {\n",
    "            overlays[i].style.display = 'none';\n",
    "        }\n",
    "        // Re-enable scrolling on body\n",
    "        document.body.style.overflow = 'auto';\n",
    "        \"\"\"\n",
    "        driver.execute_script(script)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error closing modal: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "### WEBSCRAPER ACTIVIATION\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Enhanced Glassdoor jobs scraper...\")\n",
    "    \n",
    "    # Configure the number of jobs to scrape\n",
    "    max_jobs = None  # Set to None to scrape all jobs, or a number to limit\n",
    "    max_show_more_attempts = 60  # Should be enough to get all jobs\n",
    "    get_job_details = False  # Set to True to get detailed job information\n",
    "    \n",
    "    # Use the enhanced scraper\n",
    "    jobs = enhanced_scraper(max_jobs, max_show_more_attempts, get_job_details)\n",
    "    \n",
    "    if jobs:\n",
    "        # Save to CSV\n",
    "        csv_file = f\"glassdoor__jobs_detailed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        save_to_csv(jobs, filename=csv_file)\n",
    "        \n",
    "        # Display some stats\n",
    "        print(\"\\nSummary of scraped data:\")\n",
    "        print(f\"Total jobs found: {len(jobs)}\")\n",
    "        \n",
    "        # Count jobs by company\n",
    "        companies = {}\n",
    "        for job in jobs:\n",
    "            company = job.get('company', 'Unknown')\n",
    "            companies[company] = companies.get(company, 0) + 1\n",
    "        \n",
    "        print(\"\\nTop companies:\")\n",
    "        sorted_companies = sorted(companies.items(), key=lambda x: x[1], reverse=True)\n",
    "        for company, count in sorted_companies[:5]:\n",
    "            print(f\"  {company}: {count} jobs\")\n",
    "            \n",
    "        # Print job types if available\n",
    "        job_types = {}\n",
    "        for job in jobs:\n",
    "            job_type = job.get('job_type', 'Not specified')\n",
    "            job_types[job_type] = job_types.get(job_type, 0) + 1\n",
    "            \n",
    "        if len(job_types) > 1:  # Only show if we have job type information\n",
    "            print(\"\\nJob types:\")\n",
    "            sorted_job_types = sorted(job_types.items(), key=lambda x: x[1], reverse=True)\n",
    "            for job_type, count in sorted_job_types:\n",
    "                print(f\"  {job_type}: {count} jobs\")\n",
    "    else:\n",
    "        print(\"No jobs were found. Please check the error messages above.\")\n",
    "        \n",
    "        # Additional troubleshooting instructions\n",
    "        print(\"\\nTroubleshooting steps:\")\n",
    "        print(\"1. Check if Glassdoor is detecting automation - try these solutions:\")\n",
    "        print(\"   - Add more random delays between actions\")\n",
    "        print(\"   - Use a browser profile with existing cookies\")\n",
    "        print(\"   - Try a headful browser mode to manually bypass CAPTCHA\")\n",
    "        print(\"2. Try running with different options:\")\n",
    "        print(\"   - Set get_job_details=False to only scrape basic information\")\n",
    "        print(\"   - Use a VPN to access from a different location\")\n",
    "        print(\"   - Try a different browser (Firefox via geckodriver)\")\n",
    "        print(\"   - Consider using Puppeteer or Playwright instead of Selenium\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
